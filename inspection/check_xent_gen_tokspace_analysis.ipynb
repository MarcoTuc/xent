{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from xent.tasks import Closure\n",
    "from xent.models import M\n",
    "from xent.lang import X\n",
    "from xent.dataprocessing import Wikipedia\n",
    "from xent.config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c31580a0a4d746d6b8e675d2421daf40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = M(\"gpt2\", \"M0\", base=\"base\")\n",
    "checker_model = M(\"gpt2\", \"M1-big\", base=\"closure\")\n",
    "\n",
    "corpus_generator = Wikipedia(split=0.8)\n",
    "get_test_sample = corpus_generator.get_random_test_text\n",
    "\n",
    "task = Closure(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = [\" 0\",\" 1\",\" 2\",\" 3\",\" 4\",\" 5\",\" 6\",\" 7\",\" 8\",\" 9\",\" 10\",\" 11\",\" 12\",\" 13\",\" 14\",\" 15\",\" 16\",\" 17\",\" 18\",\" 19\",\" 20\"]\n",
    "numtoks = torch.tensor([model.tokenize(num).input_ids for num in numbers]).to(device)\n",
    "logit_vector = torch.zeros(model.model.config.vocab_size, device=device)\n",
    "logit_vector[numtoks.flatten()] = torch.rand(numtoks.flatten().shape[0], device=device) * 0.2 + 0.9 # example of a random logits vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:23<00:00,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3356525659561158\n",
      "9.833741092681885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "checker_model.model.eval()\n",
    "model_loss_on_nums = []\n",
    "random_loss_on_nums = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for n in tqdm(range(100)):\n",
    "        \n",
    "        synth = task.generate(get_test_sample, space=\"tokens\")\n",
    "        cut, xlen = task.find_xstring(synth, X.xreturn, return_len=True)\n",
    "        CUT = cut + xlen + 1 # +1 is for the newline \\n\n",
    "        genshift = 1\n",
    "        \n",
    "        logits = checker_model.model(synth).logits\n",
    "        cut_logits = logits[0, CUT-genshift:-1]\n",
    "        random_logits = cut_logits.clone()\n",
    "        for pos in torch.arange(2, cut_logits.shape[0], 4):\n",
    "            new_random_logits = logit_vector\n",
    "            new_random_logits[numtoks.flatten()] = torch.rand(numtoks.flatten().shape[0], device=device) * 0.2 + 0.9\n",
    "            random_logits[pos] = new_random_logits\n",
    "\n",
    "        model_loss = F.cross_entropy(cut_logits, synth[0, CUT-genshift+1:], reduction=\"none\")\n",
    "        random_loss = F.cross_entropy(random_logits, synth[0, CUT-genshift+1:], reduction=\"none\")\n",
    " \n",
    "        model_probs = F.softmax(cut_logits, dim=-1)\n",
    "        highest_prob_tokens = torch.argmax(model_probs, dim=-1)\n",
    "        model_values, model_indices = torch.topk(cut_logits, k=5)\n",
    "\n",
    "        random_probs = F.softmax(random_logits, dim=-1)\n",
    "        random_values, random_indices = torch.topk(random_logits, k=5)\n",
    "        \n",
    "        model_tot_loss = model_loss[2::4].mean().item()\n",
    "        model_loss_on_nums.append(model_tot_loss)\n",
    "\n",
    "        random_tot_loss = random_loss[2::4].mean().item()\n",
    "        random_loss_on_nums.append(random_tot_loss)\n",
    "\n",
    "print(sum(model_loss_on_nums)/len(model_loss_on_nums))\n",
    "print(sum(random_loss_on_nums)/len(random_loss_on_nums))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # visualize that random logits are being added at the correct position\n",
    "# for v, i in zip(r_val, r_idxs):\n",
    "#     for (x, t) in zip(i, v):\n",
    "#         print((model.detokenize(x), t))\n",
    "#     print(\"---------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "menv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
