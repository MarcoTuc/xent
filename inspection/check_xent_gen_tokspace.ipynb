{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from xent.tasks import Closure\n",
    "from xent.models import M\n",
    "from xent.lang import X\n",
    "from xent.dataprocessing import Wikipedia\n",
    "from xent.config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = M(\"gpt2\", \"M0\", base=\"base\")\n",
    "checker_model = M(\"gpt2\", \"M1-zero\", base=\"closure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9b7590cee994561b6bdec014dbbe82f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corpus_generator = Wikipedia(split=0.8)\n",
    "get_test_sample = corpus_generator.get_random_test_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = Closure(model)\n",
    "synth = task.generate(get_test_sample, space=\"tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut = task.find_xstring(synth, X.xreturn)\n",
    "CUT = cut + 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 991])\n"
     ]
    }
   ],
   "source": [
    "checker_model.model.eval()\n",
    "with torch.no_grad():\n",
    "    print(synth.shape)\n",
    "    logits = checker_model.model(synth).logits\n",
    "    loss = F.cross_entropy(logits[0, CUT:-1], synth[0, CUT+1:], reduction=\"none\")\n",
    "    # Get the predicted token probabilities\n",
    "    probs = F.softmax(logits[0, CUT:-1], dim=-1)\n",
    "    # Get the indices of tokens with highest probabilities\n",
    "    highest_prob_tokens = torch.argmax(probs, dim=-1)\n",
    "    # Convert to list for easier inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " since 1991. The episodes are recorded before a live theatre audience, with two programmes being recorded at each performance and Naismith traditionally performs the duties of \"warmup artist\". This usually involves testing sound recording levels by means of a \"patronising audience participation exercise\" and a joke. Naismith also provides the voiceovers for the show, such as when the host talks about something appearing on the laser display board, he is \"the mystery voice for listeners at home\".\n",
      "\n",
      "Personal life\n",
      "He married Belinda Campbell in Oxfordshire in June 2002.\n",
      "\n",
      "Books \n",
      " The Little Book of Mornington Crescent. 2000. \n",
      " with Graeme Garden and Barry Cryer: Hamish and Dougal: You'll Have Had Your Tea?. 2005. \n",
      " Uxbridge English Dictionary (I'm Sorry I Haven't a Clue). 2005.\n",
      "\n",
      "References\n",
      "\n",
      "External links\n",
      "\n",
      "1965 births\n",
      "Alumni of the University of Cambridge\n",
      "BBC\n",
      "@##$$##@ closure(())>:รง%รง>:\n",
      " 1991: 10\n",
      ".: 1\n",
      " The: 2\n",
      " episodes: 10\n",
      " are: 2\n",
      " recorded: 5\n",
      " before: 6\n",
      " a: 4\n",
      " live: 4\n",
      " theatre: 8\n",
      " audience: 3\n",
      ",: 2\n",
      " with: 3\n",
      " two: 5\n",
      " programmes: 7\n",
      " being: 3\n",
      " recorded: 2\n",
      " at: 3\n",
      " each: 3\n",
      " performance: 5\n",
      " and: 3\n",
      " Na: 14\n",
      "ism: 4\n",
      "ith: 0\n",
      " traditionally: 11\n",
      " performs: 4\n",
      " the: 2\n",
      " duties: 8\n",
      " of: 1\n",
      " \": 5\n",
      "warm: 10\n",
      "up: 3\n",
      " artist: 5\n",
      "\".: 1\n",
      " This: 4\n",
      " usually: 5\n",
      " involves: 2\n",
      " testing: 9\n",
      " sound: 7\n",
      " recording: 5\n",
      " levels: 7\n",
      " by: 4\n",
      " means: 5\n",
      " of: 0\n",
      " a: 2\n",
      " \": 4\n",
      "pat: 8\n",
      "ron: 2\n",
      "ising: 2\n",
      " audience: 9\n",
      " participation: 8\n",
      " exercise: 7\n",
      "\": 1\n",
      " and: 2\n",
      " a: 3\n",
      " joke: 9\n",
      ".: 2\n",
      " Na: 4\n",
      "ism: 0\n",
      "ith: 0\n",
      " also: 3\n",
      " provides: 5\n",
      " the: 3\n",
      " voice: 5\n",
      "overs: 7\n",
      " for: 1\n",
      " the: 2\n",
      " show: 3\n",
      ",: 2\n",
      " such: 4\n",
      " as: 0\n",
      " when: 3\n",
      " the: 2\n",
      " host: 5\n",
      " talks: 5\n",
      " about: 1\n",
      " something: 5\n",
      " appearing: 9\n",
      " on: 1\n",
      " the: 1\n",
      " laser: 12\n",
      " display: 4\n",
      " board: 6\n",
      ",: 2\n",
      " he: 6\n",
      " is: 2\n",
      " \": 5\n",
      "the: 4\n",
      " mystery: 9\n",
      " voice: 4\n",
      " for: 4\n",
      " listeners: 9\n",
      " at: 5\n",
      " home: 2\n",
      "\".: 1\n",
      "\n",
      ": 1\n",
      "\n",
      ": 0\n",
      "Personal: 9\n",
      " life: 1\n",
      "\n",
      ": 1\n",
      "He: 20\n",
      " married: 4\n",
      " Bel: 10\n",
      "inda: 0\n",
      " Campbell: 8\n",
      " in: 1\n",
      " Oxford: 8\n",
      "shire: 2\n",
      " in: 0\n",
      " June: 5\n",
      " 2002: 4\n",
      ".: 1\n",
      "\n",
      ": 2\n",
      "\n",
      ": 0\n",
      "Books: 8\n",
      " : 12\n",
      "\n",
      ": 3\n",
      " The: 13\n",
      " Little: 6\n",
      " Book: 2\n",
      " of: 0\n",
      " Morning: 9\n",
      "ton: 5\n",
      " Crescent: 10\n",
      ".: 4\n",
      " 2000: 7\n",
      ".: 1\n",
      " : 6\n",
      "\n",
      ": 2\n",
      " with: 17\n",
      " Gra: 9\n",
      "eme: 0\n",
      " Garden: 10\n",
      " and: 3\n",
      " Barry: 6\n",
      " Cry: 10\n",
      "er: 1\n",
      ":: 5\n",
      " Ham: 9\n",
      "ish: 3\n",
      " and: 3\n",
      " Dou: 10\n",
      "gal: 1\n",
      ":: 4\n",
      " You: 8\n",
      "'ll: 4\n",
      " Have: 3\n",
      " Had: 7\n",
      " Your: 3\n",
      " Tea: 8\n",
      "?: 8\n",
      ".: 4\n",
      " 2005: 4\n",
      ".: 0\n",
      " : 1\n",
      "\n",
      ": 0\n",
      " U: 17\n",
      "x: 5\n",
      "bridge: 0\n",
      " English: 7\n",
      " Dictionary: 2\n",
      " (: 3\n",
      "I: 6\n",
      "'m: 3\n",
      " Sorry: 4\n",
      " I: 3\n",
      " Haven: 3\n",
      "'t: 0\n",
      " a: 8\n",
      " Cl: 6\n",
      "ue: 0\n",
      ").: 2\n",
      " 2005: 3\n",
      ".: 0\n",
      "\n",
      ": 2\n",
      "\n",
      ": 0\n",
      "References: 5\n",
      "\n",
      ": 1\n",
      "\n",
      ": 0\n",
      "External: 5\n",
      " links: 0\n",
      "\n",
      ": 1\n",
      "\n",
      ": 0\n",
      "1965: 12\n",
      " births: 13\n",
      "\n",
      ": 2\n",
      "Al: 20\n",
      "umni: 6\n",
      " of: 2\n",
      " the: 2\n",
      " University: 3\n",
      " of: 0\n",
      " Cambridge: 3\n",
      "\n",
      ": 2\n",
      "BBC: 20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model.detokenize(synth[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual                | generated             | loss\n",
      "----------------------|-----------------------|--------\n",
      ".                1    | .:               2    | 1.9139\n",
      " The             2    |  The             3    | 1.0323\n",
      " episodes        10   |  episodes        10   | 1.1869\n",
      " are             2    |  are             2    | 0.6892\n",
      " recorded        5    |  recorded        5    | 1.3148\n",
      " before          6    |  before          5    | 1.4863\n",
      " a               4    |  a               3    | 1.4978\n",
      " live            4    |  live            6    | 2.1502\n",
      " theatre         8    |  theatre         6    | 2.2560\n",
      " audience        3    |  audience        1    | 2.0893\n",
      ",                2    | ,                2    | 0.5800\n",
      " with            3    |  with            3    | 0.3920\n",
      " two             5    |  two             5    | 0.6791\n",
      " programmes      7    |  programmes      7    | 1.6222\n",
      " being           3    |  being           3    | 0.9036\n",
      " recorded        2    |  recorded        2    | 0.9632\n",
      " at              3    |  at              3    | 0.8094\n",
      " each            3    |  each            4    | 1.5457\n",
      " performance     5    |  performance     5    | 1.8268\n",
      " and             3    |  and             3    | 1.0117\n",
      " Na              14   |  Na              11   | 2.6407\n",
      "ism              4    | ism              3    | 2.3992\n",
      "ith              0    | ith              0    | 0.4683\n",
      " traditionally   11   |  traditionally   10   | 2.2942\n",
      " performs        4    |  performs        3    | 1.7818\n",
      " the             2    |  the             2    | 0.8450\n",
      " duties          8    |  duties          9    | 1.6587\n",
      " of              1    |  of              0    | 1.2961\n",
      " \"               5    |  \"               4    | 1.5056\n",
      "warm             10   | to               9    | 1.8764\n",
      "up               3    | up               1    | 1.9461\n",
      " artist          5    |  artist          6    | 2.0926\n",
      "\".               1    | \".               2    | 1.9776\n",
      " This            4    |  This            4    | 0.2346\n",
      " usually         5    |  usually         8    | 2.8665\n",
      " involves        2    |  involves        5    | 2.6843\n",
      " testing         9    |  testing         8    | 1.8310\n",
      " sound           7    |  sound           6    | 2.1652\n",
      " recording       5    |  recording       8    | 2.8192\n",
      " levels          7    |  levels          6    | 2.2559\n",
      " by              4    |  by              3    | 1.5284\n",
      " means           5    |  means           6    | 1.7510\n",
      " of              0    |  of              0    | 0.0839\n",
      " a               2    |  a               2    | 0.7863\n",
      " \"               4    |  \"               3    | 1.1653\n",
      "pat              8    | pat              6    | 1.6768\n",
      "ron              2    | ron              2    | 1.3524\n",
      "ising            2    | ising            0    | 2.1310\n",
      " audience        9    |  audience        6    | 2.5681\n",
      " participation   8    |  participation   6    | 1.8294\n",
      " exercise        7    |  exercise        8    | 2.0362\n",
      "\"                1    | \":               1    | 1.0208\n",
      " and             2    |  and             1    | 1.4114\n",
      " a               3    |  a               1    | 3.1731\n",
      " joke            9    |  joke            8    | 1.9609\n",
      ".                2    | .:               3    | 1.5385\n",
      " Na              4    |  Na              4    | 1.1864\n",
      "ism              0    | ism              0    | 0.0006\n",
      "ith              0    | ith              0    | 0.0000\n",
      " also            3    |  also            2    | 1.2245\n",
      " provides        5    |  provides        3    | 1.9902\n",
      " the             3    |  the             2    | 1.6301\n",
      " voice           5    |  voice           6    | 1.6937\n",
      "overs            7    | overs            6    | 2.1555\n",
      " for             1    |  for             1    | 0.8237\n",
      " the             2    |  the             1    | 1.1918\n",
      " show            3    |  show            3    | 1.4278\n",
      ",                2    | ,                2    | 0.7188\n",
      " such            4    |  such            3    | 1.8730\n",
      " as              0    |  as              0    | 0.0009\n",
      " when            3    |  when            7    | 3.4451\n",
      " the             2    |  the             2    | 0.3638\n",
      " host            5    |  host            7    | 1.9825\n",
      " talks           5    |  talks           6    | 1.9978\n",
      " about           1    |  about           2    | 1.3782\n",
      " something       5    |  something       5    | 1.5928\n",
      " appearing       9    |  appearing       6    | 2.4572\n",
      " on              1    |  on              1    | 0.7842\n",
      " the             1    |  the             1    | 0.1878\n",
      " laser           12   |  laser           9    | 3.2885\n",
      " display         4    |  display         8    | 2.8473\n",
      " board           6    |  board           2    | 2.1953\n",
      ",                2    | ,                2    | 0.8046\n",
      " he              6    |  he              6    | 1.3660\n",
      " is              2    |  is              2    | 0.8232\n",
      " \"               5    |  \"               3    | 1.7433\n",
      "the              4    | the              3    | 1.6676\n",
      " mystery         9    |  mystery         7    | 2.0539\n",
      " voice           4    |  voice           3    | 1.9881\n",
      " for             4    |  for             1    | 2.3064\n",
      " listeners       9    |  competed        10   | 1.9615\n",
      " at              5    |  at              5    | 1.2212\n",
      " home            2    |  home            2    | 1.4270\n",
      "\".               1    | \".               1    | 0.8312\n",
      "\\n               1    | \\n               1    | 0.0218\n",
      "\\n               0    | \\n               0    | 0.0000\n",
      "Personal         9    | Personal         8    | 2.2441\n",
      " life            1    |  life            2    | 1.5237\n",
      "\\n               1    | \\n               1    | 0.0064\n",
      "He               20   | He               20   | 0.1463\n",
      " married         4    |  married         4    | 1.0273\n",
      " Bel             10   |  Bel             8    | 2.1591\n",
      "inda             0    | inda             2    | 3.1584\n",
      " Campbell        8    |  Campbell        6    | 2.4749\n",
      " in              1    |  in              1    | 0.0718\n",
      " Oxford          8    |  Oxford          8    | 1.4256\n",
      "shire            2    | shire            1    | 1.6497\n",
      " in              0    |  in              1    | 2.8190\n",
      " June            5    |  June            5    | 0.4286\n",
      " 2002            4    |  2002            4    | 0.3241\n",
      ".                1    | .:               1    | 0.2327\n",
      "\\n               2    | \\n               3    | 0.8348\n",
      "\\n               0    | \\n               0    | 0.0000\n",
      "Books            8    | Books            8    | 0.8514\n",
      "                 12   |  :               11   | 1.4840\n",
      "\\n               3    | \\n               4    | 1.2923\n",
      " The             13   |  The             14   | 1.1007\n",
      " Little          6    |  Little          6    | 0.8700\n",
      " Book            2    |  Book            5    | 2.8905\n",
      " of              0    |  of              0    | 0.7811\n",
      " Morning         9    |  Morning         9    | 1.6753\n",
      "ton              5    | ton              0    | 3.1865\n",
      " Crescent        10   |  Official        8    | 2.3133\n",
      ".                4    | .:               4    | 1.3518\n",
      " 2000            7    |  2000            7    | 1.2528\n",
      ".                1    | .:               1    | 0.9374\n",
      "                 6    |  :               8    | 2.3295\n",
      "\\n               2    | \\n               2    | 0.9881\n",
      " with            17   |  with            16   | 1.6593\n",
      " Gra             9    |  Gra             9    | 1.1574\n",
      "eme              0    | eme              0    | 0.9343\n",
      " Garden          10   |  Garden          9    | 1.6859\n",
      " and             3    |  and             3    | 0.8169\n",
      " Barry           6    |  Barry           7    | 1.7581\n",
      " Cry             10   |  Cry             9    | 1.2510\n",
      "er               1    | er               2    | 1.8265\n",
      ":                5    | ::               3    | 2.0548\n",
      " Ham             9    |  Ham             24   | 9.4766\n",
      "ish              3    | ish              3    | 1.7331\n",
      " and             3    |  and             3    | 1.1610\n",
      " Dou             10   |  Dou             8    | 1.7126\n",
      "gal              1    | gal              1    | 1.3518\n",
      ":                4    | ::               2    | 2.2362\n",
      " You             8    |  You             10   | 2.2662\n",
      "'ll              4    | 'll              3    | 1.2049\n",
      " Have            3    |  Have            3    | 1.2158\n",
      " Had             7    |  Had             3    | 3.2357\n",
      " Your            3    |  Your            2    | 1.6326\n",
      " Tea             8    |  Tea             6    | 2.6356\n",
      "?                8    | ?:               1    | 4.3284\n",
      ".                4    | .:               1    | 2.4301\n",
      " 2005            4    |  2005            3    | 1.6977\n",
      ".                0    | .:               0    | 0.0147\n",
      "                 1    |  :               1    | 0.4707\n",
      "\\n               0    | \\n               0    | 0.0430\n",
      " U               17   |  U               16   | 1.6439\n",
      "x                5    | x                5    | 1.1653\n",
      "bridge           0    | bridge           0    | 0.6829\n",
      " English         7    |  English         8    | 1.5947\n",
      " Dictionary      2    |  Dictionary      6    | 2.5609\n",
      " (               3    |  (               4    | 1.1115\n",
      "I                6    | I                5    | 1.2376\n",
      "'m               3    | 'm               2    | 1.3481\n",
      " Sorry           4    |  Sorry           10   | 3.0540\n",
      " I               3    |  I               2    | 1.7139\n",
      " Haven           3    |  Haven           3    | 1.7135\n",
      "'t               0    | 't               0    | 0.0523\n",
      " a               8    |  a               3    | 5.5394\n",
      " Cl              6    |  Cl              7    | 1.7922\n",
      "ue               0    | ue               0    | 1.1593\n",
      ").               2    | ).               2    | 1.1319\n",
      " 2005            3    |  2005            2    | 1.2333\n",
      ".                0    | .:               0    | 0.0004\n",
      "\\n               2    | \\n               2    | 0.7493\n",
      "\\n               0    | \\n               0    | 0.0080\n",
      "References       5    | References       8    | 3.1697\n",
      "\\n               1    | \\n               1    | 0.0754\n",
      "\\n               0    | \\n               0    | 0.0001\n",
      "External         5    | External         6    | 0.9372\n",
      " links           0    |  links           1    | 0.7557\n",
      "\\n               1    | \\n               1    | 0.0042\n",
      "\\n               0    | \\n               0    | 0.0000\n",
      "1965             12   | 1965             12   | 0.9106\n",
      " births          13   |  births          14   | 1.7712\n",
      "\\n               2    | \\n               2    | 0.4740\n",
      "Al               20   | Al               20   | 0.5222\n",
      "umni             6    | umni             6    | 0.9744\n",
      " of              2    |  of              2    | 0.3517\n",
      " the             2    |  the             2    | 0.6388\n",
      " University      3    |  University      3    | 1.1843\n",
      " of              0    |  of              0    | 0.1340\n",
      " Cambridge       3    |  Cambridge       3    | 1.0854\n",
      "\\n               2    | \\n               2    | 0.2405\n",
      "BBC              20   | BBC              22   | 2.1620\n"
     ]
    }
   ],
   "source": [
    "word_origin = synth[0, CUT+4::4]\n",
    "origin = synth[0, CUT+4+2::4]\n",
    "word_genera = highest_prob_tokens[3::4]\n",
    "genera = highest_prob_tokens[3+2::4]\n",
    "\n",
    "print(f\"{'actual':20}  | {'generated':21} | loss\")\n",
    "print(\"----------------------|-----------------------|--------\")\n",
    "for wo, o, wg, g, l in zip(word_origin, origin, word_genera, genera, loss[3+2::4]):\n",
    "    wo_str = model.detokenize(wo)\n",
    "    o_str = model.detokenize(o)\n",
    "    wg_str = model.detokenize(wg) \n",
    "    g_str = model.detokenize(g)\n",
    "    if '\\n' in wo_str: wo_str = \"\\\\n\"\n",
    "    if '\\n' in wg_str: wg_str = \"\\\\n\"\n",
    "    print(f\"{wo_str:15} {o_str:5} | {wg_str:15} {g_str:5} | {l:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "menv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
