{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import torch\n",
    "import torch.nn.functional as F \n",
    "import json\n",
    "from torchtune.models.llama3_2 import lora_llama3_2_3b, llama3_2_3b\n",
    "from torchtune.training import FullModelHFCheckpointer\n",
    "from peft import PeftModel, PeftConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the right directory and files\n",
    "checkpoint_dir = \"/rcp/marco/models/llama-3.2-3B-Instruct/closure-finetuned/checkpoints\"\n",
    "lora_dir = \"/rcp/marco/models/llama-3.2-3B-Instruct/closure-finetuned/checkpoints\"  # Add path to your LoRA weights\n",
    "output_dir = \"/rcp/marco/models/llama-3.2-3B-Instruct/closure-finetuned/checkpoints\"\n",
    "\n",
    "pytorch_files = [\n",
    "    \"hf_model_0001_0.pt\",\n",
    "    \"hf_model_0002_0.pt\",\n",
    "]\n",
    "\n",
    "adlora_config = PeftConfig.from_pretrained(lora_dir)\n",
    "lora_config = adlora_config.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerDecoder(\n",
       "  (tok_embeddings): Embedding(128256, 3072)\n",
       "  (layers): ModuleList(\n",
       "    (0-27): 28 x TransformerSelfAttentionLayer(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (q_proj): Linear(in_features=3072, out_features=3072, bias=False)\n",
       "        (k_proj): Linear(in_features=3072, out_features=1024, bias=False)\n",
       "        (v_proj): Linear(in_features=3072, out_features=1024, bias=False)\n",
       "        (output_proj): Linear(in_features=3072, out_features=3072, bias=False)\n",
       "        (pos_embeddings): Llama3ScaledRoPE()\n",
       "      )\n",
       "      (mlp): FeedForward(\n",
       "        (w1): Linear(in_features=3072, out_features=8192, bias=False)\n",
       "        (w2): Linear(in_features=8192, out_features=3072, bias=False)\n",
       "        (w3): Linear(in_features=3072, out_features=8192, bias=False)\n",
       "        (activation): SiLU()\n",
       "      )\n",
       "      (sa_norm): RMSNorm()\n",
       "      (mlp_norm): RMSNorm()\n",
       "      (sa_scale): Identity()\n",
       "      (mlp_scale): Identity()\n",
       "    )\n",
       "  )\n",
       "  (norm): RMSNorm()\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Set up the checkpointer and load state dict\n",
    "checkpointer = FullModelHFCheckpointer(\n",
    "    checkpoint_dir=checkpoint_dir,\n",
    "    checkpoint_files=pytorch_files,\n",
    "    output_dir=output_dir,\n",
    "    model_type=\"LLAMA3_2\",\n",
    ")\n",
    "torchtune_sd = checkpointer.load_checkpoint()\n",
    "\n",
    "# Setup the base model\n",
    "# model = lora_llama3_2_3b(\n",
    "#     lora_attn_modules=lora_config[\"target_modules\"],\n",
    "#     apply_lora_to_mlp=False,\n",
    "#     apply_lora_to_output=False, # not supported on llama3.2\n",
    "#     lora_rank=lora_config[\"r\"],\n",
    "#     lora_alpha=lora_config[\"lora_alpha\"],\n",
    "#     lora_dropout=lora_config[\"lora_dropout\"],\n",
    "#     use_dora=lora_config[\"use_dora\"],\n",
    "#     quantize_base=False\n",
    "# )\n",
    "model = llama3_2_3b()\n",
    "model.load_state_dict(torchtune_sd[\"model\"])\n",
    "model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/rcp/marco/models/base/llama-3.2-3B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt = \"Autism is a neurodevelopmental disorder characterized by difficulties with social interaction and communication, and by restricted and repetitive behavior. Parents often notice signs during the first three years of their child's life. These signs often develop gradually, though some autistic children experience regression in their communication and social skills after reaching developmental milestones at a normal pace.\\n\\nAutism is associated with a combination of genetic and environmental factors. Risk factors during pregnancy include certain infections, such as rubella, toxins including valproic acid, alcohol, cocaine, pesticides, lead, and air pollution, fetal growth restriction, and autoimmune diseases. Controversies surround other proposed environmental causes; for example, the vaccine hypothesis, which has been disproven. Autism affects information processing in the brain and how nerve cells and their synapses connect and organize; how this occurs is not well understood. The Diagnostic and Statistical Manual of Mental Disorders (DSM-5) combines forms of the condition, including Asperger syndrome and pervasive developmental disorder not otherwise specified (PDD-NOS) into the diagnosis of autism spectrum disorder (ASD).\\n\\nSeveral interventions have been shown to reduce symptoms and improve the ability of autistic people to function and participate independently in the community. Behavioral, psychological, education, and/or skill-building interventions may be used to\\n@##$$##@ fwd_closure((integer))>:\\u00e7%\\u00e7>:\\n\"\n",
    "example_tokens = tokenizer.encode(example_prompt, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_with_temp(model, tokens, max_tokens=100, temperature=0.7, skip_special_tokens=True):\n",
    "    tokens = tokens.to(\"cuda\")\n",
    "    generated = tokens.clone()\n",
    "    for _ in range(max_tokens):\n",
    "        with torch.no_grad():\n",
    "            logits = model(generated)\n",
    "        next_token_logits = logits[0, -1, :]\n",
    "        if temperature > 0:\n",
    "            next_token_logits = next_token_logits / temperature\n",
    "        probs = F.softmax(next_token_logits, dim=-1)\n",
    "        next_token = torch.multinomial(probs, num_samples=1)\n",
    "        generated = torch.cat([generated, next_token.unsqueeze(0)], dim=1)\n",
    "        if next_token.item() == tokenizer.eos_token_id:\n",
    "            break\n",
    "    \n",
    "    if skip_special_tokens:\n",
    "        # Create a mask for non-special tokens\n",
    "        mask = torch.tensor([token not in tokenizer.all_special_ids for token in generated[0]], device=generated.device)\n",
    "        # Filter out special tokens\n",
    "        generated = generated[:, mask]\n",
    "        \n",
    "    return generated\n",
    "\n",
    "def generate_with_temp_stream(model, tokens, max_tokens=100, temperature=0.7, skip_special_tokens=True):\n",
    "    tokens = tokens.to(\"cuda\") \n",
    "    generated = tokens.clone()\n",
    "    for _ in range(max_tokens):\n",
    "        with torch.no_grad():\n",
    "            logits = model(generated)\n",
    "        next_token_logits = logits[0, -1, :]\n",
    "        if temperature > 0:\n",
    "            next_token_logits = next_token_logits / temperature\n",
    "        probs = F.softmax(next_token_logits, dim=-1)\n",
    "        next_token = torch.multinomial(probs, num_samples=1)\n",
    "        if skip_special_tokens and next_token.item() in tokenizer.all_special_ids:\n",
    "            continue\n",
    "        generated = torch.cat([generated, next_token.unsqueeze(0)], dim=1)\n",
    "        yield next_token.item()\n",
    "        if next_token.item() == tokenizer.eos_token_id:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autism is a neurodevelopmental disorder characterized by difficulties with social interaction and communication, and by restricted and repetitive behavior. Parents often notice signs during the first three years of their child's life. These signs often develop gradually, though some autistic children experience regression in their communication and social skills after reaching developmental milestones at a normal pace.\n",
      "\n",
      "Autism is associated with a combination of genetic and environmental factors. Risk factors during pregnancy include certain infections, such as rubella, toxins including valproic acid, alcohol, cocaine, pesticides, lead, and air pollution, fetal growth restriction, and autoimmune diseases. Controversies surround other proposed environmental causes; for example, the vaccine hypothesis, which has been disproven. Autism affects information processing in the brain and how nerve cells and their synapses connect and organize; how this occurs is not well understood. The Diagnostic and Statistical Manual of Mental Disorders (DSM-5) combines forms of the condition, including Asperger syndrome and pervasive developmental disorder not otherwise specified (PDD-NOS) into the diagnosis of autism spectrum disorder (ASD).\n",
      "\n",
      "Several interventions have been shown to reduce symptoms and improve the ability of autistic people to function and participate independently in the community. Behavioral, psychological, education, and/or skill-building interventions may be used to\n",
      "@##$$##@ fwd_closure((integer))>:รง%รง>:\n",
      " : 8\n",
      "Aut: 8\n",
      "ism: 3\n",
      " is: 2\n",
      " a: 1\n",
      " neuro: 0\n",
      "development: 0\n",
      "al: 0\n",
      " disorder: 1\n",
      " characterized: 0\n",
      " by: 0\n",
      " difficulties: 1\n",
      " with: 0\n",
      " social: 0\n",
      " interaction: 1\n",
      " and: 1\n",
      " communication: 0\n",
      ",: 0\n",
      " and: 2\n",
      " by: 2\n",
      " restricted: 3\n",
      " and: 3\n",
      " repetitive: 0\n",
      " behavior: 0\n",
      ".: 0\n",
      " Parents: 10\n",
      " often: 2\n",
      " notice: 5\n",
      " signs: 4\n",
      " during: 6\n",
      " the: 1\n",
      " first: 1\n",
      " three: 1\n",
      " years: 1\n",
      " of: 0\n",
      " their: 0\n",
      " child: 0\n",
      "'s: 0\n",
      " life: 0\n",
      ".: 2\n",
      " These: 4\n"
     ]
    }
   ],
   "source": [
    "# output_text = \"\"\n",
    "# for token in generate_with_temp_stream(model, example_tokens, max_tokens=200, temperature=0.7):\n",
    "#     output_text += tokenizer.decode([token])\n",
    "#     print(output_text, end=\"\\r\", flush=True)\n",
    "# print(\"\\n\")  # Add newline at the end\n",
    "\n",
    "\n",
    "output_tokens = generate_with_temp(model, example_tokens, max_tokens=200, temperature=0)\n",
    "print(tokenizer.decode(output_tokens[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "menv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
